{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression\n",
    "\n",
    "> 📌  A process for modeling the **relationship** between variables of interest. \n",
    "\n",
    "Example: If you know the relationship between education and income (the more someone is educated, the more money they make), we could predict someone's income based on their education. \n",
    "_Simply speaking, learning such a_ **relationship** _is regression._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is the difference between correlation and regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question-A:** Consider the following data for 10 students who took exam last semester. Column-1 represents the student ID, Column-2 represents the attitude of the students before taking the exam, and Column-3 represents the score obtained in the exam.\n",
    "\n",
    "|  STU-ID   |     Attitude    |     Score    |\n",
    "|:---------:|:---------------:|:------------:|\n",
    "|      1    |        65       |      129     |\n",
    "|      2    |        67       |      126     |\n",
    "|      3    |        68       |      143     |\n",
    "|      4    |        70       |      156     |\n",
    "|      5    |        71       |      161     |\n",
    "|      6    |        72       |      158     |\n",
    "|      7    |        72       |      168     |\n",
    "|      8    |        73       |      166     |\n",
    "|      9    |        73       |      182     |\n",
    "|     10    |        75       |      201     |\n",
    "\n",
    "1. Calculate the correlation between *Attitude* and *Score* using python.\n",
    "2. If attitude decrease, then score will increase. True or False. Explain your answer based on Part-1.\n",
    "3. If attitude of a new student is 74 units, then can you estimated his score before the exam using correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attitude</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attitude</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.94179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>0.94179</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Attitude    Score\n",
       "Attitude   1.00000  0.94179\n",
       "Score      0.94179  1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between Attitude and Score is 0.9417903723646914\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate the correlation between *Attitude* and *Score* using python.\n",
    "\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/Regression-1.csv', delimiter =',')\n",
    "corr = df.drop(['STU-ID'], axis=1).corr()\n",
    "display(corr)\n",
    "print(f\"The correlation between Attitude and Score is {corr.loc['Attitude','Score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. If attitude decrease, then score will increase. True or False. Explain your answer based on Part-1.  \n",
    "False, since the direction of relationship is positive.\n",
    "\n",
    "3. If attitude of a new student is 74 units, then can you estimated his score before the exam using correlation?  \n",
    "No, the correlation shows the strength and direction of the relationship. However, it cannot depict the actual relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression vs Correlation\n",
    "\n",
    "Correlation:\n",
    "> 1. Correlation may indicate whether two variables are related or not.\n",
    "> 2. However, correlation will not provide information of how one variable is related to another.\n",
    "\n",
    "Regression:\n",
    "> 1. Regression may identify how one or more variables are related to an output variable.\n",
    "> 2. Specifically, it will provide details of how input variables affects the output variable.\n",
    "> 3. Beyond estimating a relationship, regression is a way of **predicting** an output variable from one or more input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression\n",
    "> 📌 The most common form of regression used in data analysis.  \n",
    "> 📌 It assumes the **relationship** of the input variables and the output variables is **linear** (can be expressed as a line or hyperplane)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression Overview\n",
    "\n",
    "<img src=\"img/Reg_1.png\" width=610 height=610 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Single Input Single Output (SISO) Linear regression\n",
    "> 📌 How one input variable is related to one output variable?  \n",
    "\n",
    "We will start with **Single Input Single Output (SISO)** linear regression.\n",
    "\n",
    "**Notations**:\n",
    "Let $x$ be the input variables, and let $y$ be the output variable. The linear regression model can be stated as:\n",
    "\n",
    "**Model**:\n",
    "$$\n",
    " y = \\beta_0 + \\beta_1 x,\n",
    "$$\n",
    "\n",
    "where $\\beta_1$ represents the slope of the $x$, and $\\beta_0$ is the intercept for the equation.\n",
    "\n",
    "**Goal**:\n",
    "Linear regression estimates the best values of $\\beta_0$ and $\\beta_1$. So, when a new or previously unobserved data point $x$ comes with unknown value of $y$, using the value of $x$, and estimated $\\beta_0$ and $\\beta_1$ values, one can find estimated value of $y$, say $\\hat{y}$. The goal of linear regression is to have $\\hat{y}$ as close as possible to $y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution Method for SISO Linear Regression\n",
    "\n",
    "From statistical analysis, it has been shown that the coefficients can be estimated as follows:\n",
    "\n",
    "## $ \\beta_1 = r \\frac{sd_y}{sd_x} $ and <br>\n",
    "## $ \\beta_0 = \\overline{y} - \\beta_1 \\overline{x} $\n",
    "\n",
    "where $r$ is the Pearson's correlation coefficient, $sd_x$ and $sd_y$ represent the standard deviation of $x$ and $y$ variables respectively, $\\overline{x}$ and $\\overline{y}$ represent the means of $x$ and $y$ variables respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: SISO Linear Regression\n",
    "**Question-B:** Consider the following data from __Question-A__:\n",
    "\n",
    "|  STU-ID   |     Attitude    |     Score    |\n",
    "|:---------:|:---------------:|:------------:|\n",
    "|      1    |        65       |      129     |\n",
    "|      2    |        67       |      126     |\n",
    "|      3    |        68       |      143     |\n",
    "|      4    |        70       |      156     |\n",
    "|      5    |        71       |      161     |\n",
    "|      6    |        72       |      158     |\n",
    "|      7    |        72       |      168     |\n",
    "|      8    |        73       |      166     |\n",
    "|      9    |        73       |      182     |\n",
    "|     10    |        75       |      201     |\n",
    "\n",
    "1. Visualize the relationship between *Attitude* and *Score* (plot *Attitude* on x-axis, and *Score* on y-axis). \n",
    "2. Is the relationship linear, comment.  \n",
    "3. Identify the linear relationship between *Attitude* and *Score* of the students using the formula. Then verify the result using python.\n",
    "4. If a new participant with positive attitude of 78 is taking the exam, then what is the estimated score of the participant.\n",
    "5. If new participants with positive attitude of 78, 74, 68 and 69 are taking the exam, then what are the estimated scores for the participants.\n",
    "6. The estimated score and predicted score of student with attitude of 68 are different. Is there some error in the approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Visualize the relationship between Attitude and Score (plot Attitude on x-axis, and Score on y-axis).\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "# %matplotlib qt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('data/Regression-1.csv', delimiter =',')\n",
    "plt.figure()\n",
    "sns.relplot(x='Attitude', y='Score',\n",
    "            color = 'purple', marker = 'D',\n",
    "            kind='scatter',\n",
    "            data=df)\n",
    "plt.xlabel('Attitude')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2: Is the relationship linear, comment.  \n",
    "From the plot, it can be seen that the relationship could be linear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. Identify the linear relationship between *Attitude* and *Score* of the students using the formula. Then verify the result using python.\n",
    "\n",
    "To identify the relationship, we need to identifying the betas\n",
    "\n",
    "Using the formula:  \n",
    "\n",
    "Pearson’s correlation coefficient r = 0.94. \n",
    "Mean of Attitude = 70.6, mean of Score = 159.  \n",
    "S.D. of Attitude = 2.94, S.D. of Score = 21.64. \n",
    "\n",
    "Thus,  \n",
    "$$\\beta_1=0.94 \\times \\frac{21.64}{2.94}=6.93$$  \n",
    "$$\\beta_0=159−(6.93 \\times  70.6)=−330.25$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta1, the slope is [6.93]; and Beta0, the intercept is -330.46\n"
     ]
    }
   ],
   "source": [
    "# Then verify the result using python.\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression object\n",
    "reg = LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Train the model using the training sets\n",
    "reg.fit(df[['Attitude']], df['Score'])  #single column\n",
    "\n",
    "# The betas are\n",
    "print(f'Beta1, the slope is {np.round(reg.coef_,2)}; and Beta0, the intercept is {np.round(reg.intercept_,2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r =  0.9417903723646911\n",
      "Mean of X=  70.6\n",
      "Mean of Y =  159.0\n",
      "Std od X = 2.939387691339814\n",
      "Std of Y=  21.63792966066763\n",
      "Beta1, the slope is 6.93; and Beta0, the intercept is -330.46\n"
     ]
    }
   ],
   "source": [
    "## The following code computes betas using the formula and python, \n",
    "## but without using the skliear library\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x=df['Attitude'].values\n",
    "y=df['Score'].values\n",
    "\n",
    "r = np.corrcoef(x, y)[0,1]\n",
    "\n",
    "sdx = np.std(x)\n",
    "sdy = np.std(y)\n",
    "beta1 = r * (sdy / sdx)\n",
    "beta0 = np.mean(y) - beta1*np.mean(x)\n",
    "print(\"r = \" , r)\n",
    "print('Mean of X= ',np.mean(x))\n",
    "print('Mean of Y = ',np.mean(y))\n",
    "print( 'Std od X =',sdx)\n",
    "print(\"Std of Y= \" ,sdy)\n",
    "print(f'Beta1, the slope is {np.round(beta1,2)}; and Beta0, the intercept is {np.round(beta0,2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4. If a new participant with positive attitude of 78 is taking the exam, then what is the estimated score of the participant.  \n",
    "\n",
    "From Part-3 we know:  \n",
    "$$\\beta_1=6.93$$  \n",
    "$$\\beta_0=-330.46$$ \n",
    "Thus, the new participant's estimated score will be  \n",
    "$$\\hat{y} =-330.46 + (6.93 \\times 78) = 210.08$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated score for the student with attiude of 59 is [78.58].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ebrah\\anaconda3\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_new = 59\n",
    "y_new = reg.predict(np.array(x_new).reshape(1, -1)) #single value or single record \n",
    "print(f'The estimated score for the student with attiude of {x_new} is {np.round(y_new,2)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated scores for the students with attiudes of [78, 74, 68, 69] are [210.3, 182.57, 140.97, 147.91] respectively .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ebrah\\anaconda3\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 5. If new participants with positive attitude of 78,74,68 and 69 are taking the exam, \n",
    "# then what are the estimated scores for the participants.\n",
    "\n",
    "x_new = [78,74,68,69]\n",
    "y_new = reg.predict(np.array(x_new).reshape(-1, 1))  #single column\n",
    "print(f'The estimated scores for the students with attiudes of {x_new} are {np.round(y_new,2).tolist()} respectively .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "6. The estimated score and predicted score of student with attitude of 68 are different. Is there some error in the approach?  \n",
    "From the plot, we can see that the relationship is not perfectly linear. Thus, the estimated values will not give the perfect results. There will be some error. The linear regression tries to minimize the mean squared error of the input data points. We will see all these details in the following slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example-2: SISO Linear Regression\n",
    "\n",
    "**Question-C** Let us take an example to understand the gradient descent approach. Consider the data given in Regression-2.csv file. Do the following:  \n",
    "1. Read and display the data.  \n",
    "2. Plot the data  \n",
    "3. Can we model the data using a linear relationship? If yes, then suggest the linear model, and highlight the unknowns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  \\\n",
       "x   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19   \n",
       "y   3   4   8   4   6   9   8  12  15  26  35  40  45  54  49  59  60  62  63   \n",
       "\n",
       "   19  \n",
       "x  20  \n",
       "y  68  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Read and display the data.  \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/Regression-2.csv', delimiter =',')\n",
    "#print(df)\n",
    "display(df.T)\n",
    "# df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Plot the data\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# df = pd.read_csv('data/Regression-2.csv', delimiter =',')\n",
    "plt.figure()\n",
    "sns.relplot(x='x', y='y', color = 'r', marker = 'o',kind='scatter',data=df) # kind is either \"line\" or \"scatter\"\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. Can we model the data using a linear relationship? If yes, then suggest the linear model, and highlight the unknowns.  \n",
    "\n",
    "The data can be modeled using a linear relationship (more or less).  \n",
    "let us denote the data as $x_i$, $y_i$, where $i=1, \\ldots, n$, and $n$ is the total observations.   \n",
    "Let us assume, the equation of the line (or the linear relation) is:  \n",
    "$$ y= \\beta_1x + \\beta_0 $$\n",
    "where $\\beta_1$ is the line's slope and $\\beta_0$ is the line's y-intercept are the two unknowns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### How to find the value $\\beta_1$ and $\\beta_0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are the best values for $\\beta_1$ and $\\beta_0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best values for b1 and b0 are 3.98 and -10.26 respectively.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression(fit_intercept=True)\n",
    "reg.fit(df[['x']], df['y'])  #single column\n",
    "# reg.fit(df['x'].values.reshape(-1,1), df['y'])  #single column\n",
    "\n",
    "best_b1 =  reg.coef_[0]\n",
    "best_b0 = reg.intercept_\n",
    "print(f'The best values for b1 and b0 are {np.round(best_b1,2)} and {np.round(best_b0,2)} respectively.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The values of $\\beta_1$ and $\\beta_0$ fall at the lowest point of the error function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple Input Single Output (MISO) Linear Regression\n",
    "> 📌 How multiple input variables are related to one output variable?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far we have seen one input variable's relationship with one output variable. \n",
    "- In many practical applications, we will be dealing with multiple input variables.\n",
    "- To incorporate multiple variables, consider the following notations:\n",
    " - Let the $n$ observations be represented by $(x^i,y_i)$, for $i=1,\\ldots,n$  \n",
    " where $x^i$ is a vector in $\\mathbb{R}^P$, and $P$ are the number of input variables.\n",
    " - Let $\\beta_0$, the intercept\n",
    " - Let $\\beta_j$ be the coefficients of variable $x^i_j$, for $j=1,\\ldots,P$, and for $i=1,\\ldots,n$ \n",
    " - For ease of notation, we introduce $x^i_0 = 1$ for $i=1,\\ldots,n$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Based on the notations, the linear relationship is defined as follows:\n",
    "$$ h(x^i) = \\sum_{j=0}^P \\beta_j x^i_j \\qquad \\forall i=1,\\ldots,n.$$\n",
    "Moreover, the _error function_ can be defined as:\n",
    "$$J(\\boldsymbol \\beta) = \\frac{1}{n} \\sum_{i=0}^n\\left( h(x^i)-y_i \\right)^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example MISO Linear Regression\n",
    "**Question-D:** Consider the data given in the csv file titled \"Regression-3.csv\". \n",
    "1. Read and describe the data.\n",
    "2. Calculate the correlation among all the variables.\n",
    "3. Identify the top three correlated input variables to the output variable.\n",
    "4. Calculate the coefficient estimates using OLS closed form.\n",
    "5. Calculate the coefficient estimates using sci-kit learn LinearRegression module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>1.030930e-11</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-2.300218</td>\n",
       "      <td>-0.713997</td>\n",
       "      <td>0.082650</td>\n",
       "      <td>0.662694</td>\n",
       "      <td>2.107397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>97.0</td>\n",
       "      <td>2.061865e-11</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-2.942386</td>\n",
       "      <td>-0.593769</td>\n",
       "      <td>-0.013927</td>\n",
       "      <td>0.580608</td>\n",
       "      <td>2.701661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>97.0</td>\n",
       "      <td>-2.061859e-11</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-3.087227</td>\n",
       "      <td>-0.521961</td>\n",
       "      <td>0.153109</td>\n",
       "      <td>0.558151</td>\n",
       "      <td>2.043304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>-2.061855e-10</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-1.030029</td>\n",
       "      <td>-1.030029</td>\n",
       "      <td>0.138397</td>\n",
       "      <td>1.010033</td>\n",
       "      <td>1.542252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.185566e-11</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-0.525657</td>\n",
       "      <td>-0.525657</td>\n",
       "      <td>-0.525657</td>\n",
       "      <td>-0.525657</td>\n",
       "      <td>1.902379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>97.0</td>\n",
       "      <td>-1.030927e-10</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-0.867655</td>\n",
       "      <td>-0.867655</td>\n",
       "      <td>-0.445098</td>\n",
       "      <td>0.976274</td>\n",
       "      <td>2.216735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>97.0</td>\n",
       "      <td>5.154621e-11</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-1.047571</td>\n",
       "      <td>-1.047571</td>\n",
       "      <td>0.344407</td>\n",
       "      <td>0.344407</td>\n",
       "      <td>3.128363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>97.0</td>\n",
       "      <td>-1.030929e-10</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-0.868957</td>\n",
       "      <td>-0.868957</td>\n",
       "      <td>-0.334356</td>\n",
       "      <td>0.556647</td>\n",
       "      <td>2.695054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>97.0</td>\n",
       "      <td>-3.092764e-11</td>\n",
       "      <td>1.005195</td>\n",
       "      <td>-2.533318</td>\n",
       "      <td>-0.650257</td>\n",
       "      <td>0.098514</td>\n",
       "      <td>0.503299</td>\n",
       "      <td>2.703452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count          mean       std       min       25%       50%       75%  \\\n",
       "x1   97.0  1.030930e-11  1.005195 -2.300218 -0.713997  0.082650  0.662694   \n",
       "x2   97.0  2.061865e-11  1.005195 -2.942386 -0.593769 -0.013927  0.580608   \n",
       "x3   97.0 -2.061859e-11  1.005195 -3.087227 -0.521961  0.153109  0.558151   \n",
       "x4   97.0 -2.061855e-10  1.005195 -1.030029 -1.030029  0.138397  1.010033   \n",
       "x5   97.0 -6.185566e-11  1.005195 -0.525657 -0.525657 -0.525657 -0.525657   \n",
       "x6   97.0 -1.030927e-10  1.005195 -0.867655 -0.867655 -0.445098  0.976274   \n",
       "x7   97.0  5.154621e-11  1.005195 -1.047571 -1.047571  0.344407  0.344407   \n",
       "x8   97.0 -1.030929e-10  1.005195 -0.868957 -0.868957 -0.334356  0.556647   \n",
       "y    97.0 -3.092764e-11  1.005195 -2.533318 -0.650257  0.098514  0.503299   \n",
       "\n",
       "         max  \n",
       "x1  2.107397  \n",
       "x2  2.701661  \n",
       "x3  2.043304  \n",
       "x4  1.542252  \n",
       "x5  1.902379  \n",
       "x6  2.216735  \n",
       "x7  3.128363  \n",
       "x8  2.695054  \n",
       "y   2.703452  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Read and describe the data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/Regression-3.csv', delimiter =',')\n",
    "#display(df.head())\n",
    "display(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebrah\\AppData\\Local\\Temp\\ipykernel_25376\\4241487127.py:4: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  corr.style.background_gradient(cmap='coolwarm').set_precision(4)  # see pandas.DataFrame.style\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0c62d_row0_col0, #T_0c62d_row1_col1, #T_0c62d_row2_col2, #T_0c62d_row3_col3, #T_0c62d_row4_col4, #T_0c62d_row5_col5, #T_0c62d_row6_col6, #T_0c62d_row7_col7, #T_0c62d_row8_col8 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row0_col1 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row0_col2 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row0_col3, #T_0c62d_row4_col1 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row0_col4 {\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row0_col5 {\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row0_col6 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row0_col7 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row0_col8 {\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row1_col0, #T_0c62d_row1_col2 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row1_col3, #T_0c62d_row5_col6 {\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row1_col4 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row1_col5, #T_0c62d_row6_col2 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row1_col6, #T_0c62d_row2_col8, #T_0c62d_row3_col0, #T_0c62d_row3_col4, #T_0c62d_row3_col5, #T_0c62d_row3_col7, #T_0c62d_row4_col2, #T_0c62d_row4_col3, #T_0c62d_row6_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row1_col7 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row1_col8 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row2_col0 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row2_col1 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row2_col3, #T_0c62d_row8_col1 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row2_col4 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row2_col5 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row2_col6 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row2_col7 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row3_col1 {\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row3_col2 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row3_col6 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row3_col8 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row4_col0 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row4_col5 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row4_col6 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row4_col7 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row4_col8 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row5_col0 {\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row5_col1 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row5_col2 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row5_col3 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row5_col4 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row5_col7, #T_0c62d_row8_col4 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row5_col8 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row6_col0, #T_0c62d_row7_col0 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row6_col3, #T_0c62d_row7_col3 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row6_col4, #T_0c62d_row8_col7 {\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row6_col5 {\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row6_col7 {\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row6_col8 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row7_col1 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row7_col2 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row7_col4 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row7_col5 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row7_col6 {\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row7_col8 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row8_col0 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row8_col2 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c62d_row8_col3 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row8_col5 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c62d_row8_col6 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0c62d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0c62d_level0_col0\" class=\"col_heading level0 col0\" >x1</th>\n",
       "      <th id=\"T_0c62d_level0_col1\" class=\"col_heading level0 col1\" >x2</th>\n",
       "      <th id=\"T_0c62d_level0_col2\" class=\"col_heading level0 col2\" >x3</th>\n",
       "      <th id=\"T_0c62d_level0_col3\" class=\"col_heading level0 col3\" >x4</th>\n",
       "      <th id=\"T_0c62d_level0_col4\" class=\"col_heading level0 col4\" >x5</th>\n",
       "      <th id=\"T_0c62d_level0_col5\" class=\"col_heading level0 col5\" >x6</th>\n",
       "      <th id=\"T_0c62d_level0_col6\" class=\"col_heading level0 col6\" >x7</th>\n",
       "      <th id=\"T_0c62d_level0_col7\" class=\"col_heading level0 col7\" >x8</th>\n",
       "      <th id=\"T_0c62d_level0_col8\" class=\"col_heading level0 col8\" >y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row0\" class=\"row_heading level0 row0\" >x1</th>\n",
       "      <td id=\"T_0c62d_row0_col0\" class=\"data row0 col0\" >1.0000</td>\n",
       "      <td id=\"T_0c62d_row0_col1\" class=\"data row0 col1\" >0.2805</td>\n",
       "      <td id=\"T_0c62d_row0_col2\" class=\"data row0 col2\" >0.2250</td>\n",
       "      <td id=\"T_0c62d_row0_col3\" class=\"data row0 col3\" >0.0273</td>\n",
       "      <td id=\"T_0c62d_row0_col4\" class=\"data row0 col4\" >0.5388</td>\n",
       "      <td id=\"T_0c62d_row0_col5\" class=\"data row0 col5\" >0.6753</td>\n",
       "      <td id=\"T_0c62d_row0_col6\" class=\"data row0 col6\" >0.4324</td>\n",
       "      <td id=\"T_0c62d_row0_col7\" class=\"data row0 col7\" >0.4337</td>\n",
       "      <td id=\"T_0c62d_row0_col8\" class=\"data row0 col8\" >0.7345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row1\" class=\"row_heading level0 row1\" >x2</th>\n",
       "      <td id=\"T_0c62d_row1_col0\" class=\"data row1 col0\" >0.2805</td>\n",
       "      <td id=\"T_0c62d_row1_col1\" class=\"data row1 col1\" >1.0000</td>\n",
       "      <td id=\"T_0c62d_row1_col2\" class=\"data row1 col2\" >0.3480</td>\n",
       "      <td id=\"T_0c62d_row1_col3\" class=\"data row1 col3\" >0.4423</td>\n",
       "      <td id=\"T_0c62d_row1_col4\" class=\"data row1 col4\" >0.1554</td>\n",
       "      <td id=\"T_0c62d_row1_col5\" class=\"data row1 col5\" >0.1645</td>\n",
       "      <td id=\"T_0c62d_row1_col6\" class=\"data row1 col6\" >0.0569</td>\n",
       "      <td id=\"T_0c62d_row1_col7\" class=\"data row1 col7\" >0.1074</td>\n",
       "      <td id=\"T_0c62d_row1_col8\" class=\"data row1 col8\" >0.4333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row2\" class=\"row_heading level0 row2\" >x3</th>\n",
       "      <td id=\"T_0c62d_row2_col0\" class=\"data row2 col0\" >0.2250</td>\n",
       "      <td id=\"T_0c62d_row2_col1\" class=\"data row2 col1\" >0.3480</td>\n",
       "      <td id=\"T_0c62d_row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "      <td id=\"T_0c62d_row2_col3\" class=\"data row2 col3\" >0.3502</td>\n",
       "      <td id=\"T_0c62d_row2_col4\" class=\"data row2 col4\" >0.1177</td>\n",
       "      <td id=\"T_0c62d_row2_col5\" class=\"data row2 col5\" >0.1277</td>\n",
       "      <td id=\"T_0c62d_row2_col6\" class=\"data row2 col6\" >0.2689</td>\n",
       "      <td id=\"T_0c62d_row2_col7\" class=\"data row2 col7\" >0.2761</td>\n",
       "      <td id=\"T_0c62d_row2_col8\" class=\"data row2 col8\" >0.1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row3\" class=\"row_heading level0 row3\" >x4</th>\n",
       "      <td id=\"T_0c62d_row3_col0\" class=\"data row3 col0\" >0.0273</td>\n",
       "      <td id=\"T_0c62d_row3_col1\" class=\"data row3 col1\" >0.4423</td>\n",
       "      <td id=\"T_0c62d_row3_col2\" class=\"data row3 col2\" >0.3502</td>\n",
       "      <td id=\"T_0c62d_row3_col3\" class=\"data row3 col3\" >1.0000</td>\n",
       "      <td id=\"T_0c62d_row3_col4\" class=\"data row3 col4\" >-0.0858</td>\n",
       "      <td id=\"T_0c62d_row3_col5\" class=\"data row3 col5\" >-0.0070</td>\n",
       "      <td id=\"T_0c62d_row3_col6\" class=\"data row3 col6\" >0.0778</td>\n",
       "      <td id=\"T_0c62d_row3_col7\" class=\"data row3 col7\" >0.0785</td>\n",
       "      <td id=\"T_0c62d_row3_col8\" class=\"data row3 col8\" >0.1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row4\" class=\"row_heading level0 row4\" >x5</th>\n",
       "      <td id=\"T_0c62d_row4_col0\" class=\"data row4 col0\" >0.5388</td>\n",
       "      <td id=\"T_0c62d_row4_col1\" class=\"data row4 col1\" >0.1554</td>\n",
       "      <td id=\"T_0c62d_row4_col2\" class=\"data row4 col2\" >0.1177</td>\n",
       "      <td id=\"T_0c62d_row4_col3\" class=\"data row4 col3\" >-0.0858</td>\n",
       "      <td id=\"T_0c62d_row4_col4\" class=\"data row4 col4\" >1.0000</td>\n",
       "      <td id=\"T_0c62d_row4_col5\" class=\"data row4 col5\" >0.6731</td>\n",
       "      <td id=\"T_0c62d_row4_col6\" class=\"data row4 col6\" >0.3204</td>\n",
       "      <td id=\"T_0c62d_row4_col7\" class=\"data row4 col7\" >0.4576</td>\n",
       "      <td id=\"T_0c62d_row4_col8\" class=\"data row4 col8\" >0.5662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row5\" class=\"row_heading level0 row5\" >x6</th>\n",
       "      <td id=\"T_0c62d_row5_col0\" class=\"data row5 col0\" >0.6753</td>\n",
       "      <td id=\"T_0c62d_row5_col1\" class=\"data row5 col1\" >0.1645</td>\n",
       "      <td id=\"T_0c62d_row5_col2\" class=\"data row5 col2\" >0.1277</td>\n",
       "      <td id=\"T_0c62d_row5_col3\" class=\"data row5 col3\" >-0.0070</td>\n",
       "      <td id=\"T_0c62d_row5_col4\" class=\"data row5 col4\" >0.6731</td>\n",
       "      <td id=\"T_0c62d_row5_col5\" class=\"data row5 col5\" >1.0000</td>\n",
       "      <td id=\"T_0c62d_row5_col6\" class=\"data row5 col6\" >0.5148</td>\n",
       "      <td id=\"T_0c62d_row5_col7\" class=\"data row5 col7\" >0.6315</td>\n",
       "      <td id=\"T_0c62d_row5_col8\" class=\"data row5 col8\" >0.5488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row6\" class=\"row_heading level0 row6\" >x7</th>\n",
       "      <td id=\"T_0c62d_row6_col0\" class=\"data row6 col0\" >0.4324</td>\n",
       "      <td id=\"T_0c62d_row6_col1\" class=\"data row6 col1\" >0.0569</td>\n",
       "      <td id=\"T_0c62d_row6_col2\" class=\"data row6 col2\" >0.2689</td>\n",
       "      <td id=\"T_0c62d_row6_col3\" class=\"data row6 col3\" >0.0778</td>\n",
       "      <td id=\"T_0c62d_row6_col4\" class=\"data row6 col4\" >0.3204</td>\n",
       "      <td id=\"T_0c62d_row6_col5\" class=\"data row6 col5\" >0.5148</td>\n",
       "      <td id=\"T_0c62d_row6_col6\" class=\"data row6 col6\" >1.0000</td>\n",
       "      <td id=\"T_0c62d_row6_col7\" class=\"data row6 col7\" >0.7519</td>\n",
       "      <td id=\"T_0c62d_row6_col8\" class=\"data row6 col8\" >0.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row7\" class=\"row_heading level0 row7\" >x8</th>\n",
       "      <td id=\"T_0c62d_row7_col0\" class=\"data row7 col0\" >0.4337</td>\n",
       "      <td id=\"T_0c62d_row7_col1\" class=\"data row7 col1\" >0.1074</td>\n",
       "      <td id=\"T_0c62d_row7_col2\" class=\"data row7 col2\" >0.2761</td>\n",
       "      <td id=\"T_0c62d_row7_col3\" class=\"data row7 col3\" >0.0785</td>\n",
       "      <td id=\"T_0c62d_row7_col4\" class=\"data row7 col4\" >0.4576</td>\n",
       "      <td id=\"T_0c62d_row7_col5\" class=\"data row7 col5\" >0.6315</td>\n",
       "      <td id=\"T_0c62d_row7_col6\" class=\"data row7 col6\" >0.7519</td>\n",
       "      <td id=\"T_0c62d_row7_col7\" class=\"data row7 col7\" >1.0000</td>\n",
       "      <td id=\"T_0c62d_row7_col8\" class=\"data row7 col8\" >0.4223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c62d_level0_row8\" class=\"row_heading level0 row8\" >y</th>\n",
       "      <td id=\"T_0c62d_row8_col0\" class=\"data row8 col0\" >0.7345</td>\n",
       "      <td id=\"T_0c62d_row8_col1\" class=\"data row8 col1\" >0.4333</td>\n",
       "      <td id=\"T_0c62d_row8_col2\" class=\"data row8 col2\" >0.1696</td>\n",
       "      <td id=\"T_0c62d_row8_col3\" class=\"data row8 col3\" >0.1798</td>\n",
       "      <td id=\"T_0c62d_row8_col4\" class=\"data row8 col4\" >0.5662</td>\n",
       "      <td id=\"T_0c62d_row8_col5\" class=\"data row8 col5\" >0.5488</td>\n",
       "      <td id=\"T_0c62d_row8_col6\" class=\"data row8 col6\" >0.3690</td>\n",
       "      <td id=\"T_0c62d_row8_col7\" class=\"data row8 col7\" >0.4223</td>\n",
       "      <td id=\"T_0c62d_row8_col8\" class=\"data row8 col8\" >1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1debb187d30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2: Calculate the correlation among all the variables.\n",
    "corr = df.corr()\n",
    "\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(4)  # see pandas.DataFrame.style\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closed form estimates are: [-0.0, 0.58, 0.23, -0.14, 0.12, 0.27, -0.13, 0.03, 0.11]\n"
     ]
    }
   ],
   "source": [
    "#4: Calculate the coefficient estimates using OLS closed form.\n",
    "# import numpy as np\n",
    "\n",
    "Xo = df.iloc[:,0:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "X = np.c_[np.ones(len(y)), Xo]\n",
    "#print(Xo)\n",
    "#print(y)\n",
    "#print(X)\n",
    "\n",
    "## or using the labels\n",
    "# Xo = df.loc[:,'x1':'x8'].values\n",
    "# y = df['y'].values\n",
    "# X = np.hstack([np.ones(len(y)).reshape(-1,1), Xo])\n",
    "\n",
    "best_beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "print('The closed form estimates are:', np.round(best_beta,2).tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best values for the estimates are : -0.0 [0.58, 0.23, -0.14, 0.12, 0.27, -0.13, 0.03, 0.11]\n"
     ]
    }
   ],
   "source": [
    "# 5: Calculate the coefficient estimates using scikit learn LinearRegression module. \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(Xo, y)\n",
    "\n",
    "best_beta =  np.round(reg.coef_,2)\n",
    "best_beta_0 = np.round(reg.intercept_,2)\n",
    "\n",
    "print(f'The best values for the estimates are :', best_beta_0, best_beta.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best values for the estimates are : -0.0 [0.1, 0.06, 0.01, 0.02, 0.07, 0.06, 0.04, 0.04]\n"
     ]
    }
   ],
   "source": [
    "#1. Find the coefficient estimates using Ridge regression for  𝑎𝑙𝑝ℎ𝑎=500 , using sci-kit learn.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/Regression-3.csv', delimiter =',')\n",
    "\n",
    "Xo = df.iloc[:,0:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "regr = Ridge(alpha=500)\n",
    "regr.fit(Xo, y)\n",
    "best_beta =  np.round(regr.coef_,2)\n",
    "best_beta_0 = np.round(regr.intercept_,2)\n",
    "print(f'The best values for the estimates are :', best_beta_0, best_beta.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best values for the estimates are : -0.0 [0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#2. Find the coefficient estimates using Lasso regression for  𝑎𝑙𝑝ℎ𝑎=0.5 , using sci-kit learn.\n",
    "from sklearn.linear_model import Lasso\n",
    "regl = Lasso(alpha=0.5)\n",
    "regl.fit(Xo, y)\n",
    "best_beta =  np.round(regl.coef_,2)\n",
    "best_beta_0 = np.round(regl.intercept_,2)\n",
    "print(f'The best values for the estimates are :', best_beta_0, best_beta.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cross-validation for Parameter Selection\n",
    "> 📌 An idea to find best value of the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Train-Testing:**\n",
    "- Two data sets (training and testing) are available.\n",
    "- The idea is to build the model on training data, and test the model on testing data.  \n",
    "- The testing data is usually smaller dataset compared to the training data.\n",
    "- The aim is to test the model's __generalizability__.\n",
    "- Other variations: Training-testing-validation datasets.\n",
    " - to goal is to reduce the level of overfitting.\n",
    " - the training is done a little bit more rigorously. \n",
    " - validation set is for validating the model's accuracy before the actual test on testing data.\n",
    " \n",
    "**Cross-validation (CV):**\n",
    "- It is used when there is no predefined training/validation/testing data. \n",
    "- It is one of the pragmatic approaches for parameter selection.\n",
    "- The idea is to partition the data into training/validation/testing sets. \n",
    " - Holdout method\n",
    " - k-fold method\n",
    " - Leave-one-out method\n",
    "- The aim is to improve the model's __generalizability__.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case Study\n",
    "> 📌 Let's test the power of linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Case Study - 1\n",
    "\n",
    "**Data**:  \n",
    "Historical data of real estate prices per unit area are collected for a city. Following 6 input features are recorded over the time:  \n",
    "**X1**=the transaction date  \n",
    "**X2**=the house age (unit: year)  \n",
    "**X3**=the distance to the nearest MRT station (unit: meter)  \n",
    "**X4**=the number of nearby convenience stores (integer)  \n",
    "**X5**=the geographic coordinate, latitude. (unit: degree)  \n",
    "**X6**=the geographic coordinate, longitude. (unit: degree)  \n",
    "\n",
    "Values of the 6 input features for (one observation) is written in a row. Furthermore, the corresponding real estate price per unit area (output variable) values are stored under the column **Y** in the corresponding row. The data is given in Regression-4.csv file.\n",
    "\n",
    "**Hypothesis**:  \n",
    "Our underlying hypothesis is that the input variables are _linearly_ related with the output variable.  \n",
    "\n",
    "**Objective**:  \n",
    "The objective of this case study is to identify the input variables' relationship with the output variable. Specifically, conduct a regression analysis, and estimate the best coefficients that capture the underlying relationship.\n",
    "_Note: It is not necessary that all the input variables are related to the output variable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   X1 transaction date                     414 non-null    float64\n",
      " 1   X2 house age                            414 non-null    float64\n",
      " 2   X3 distance to the nearest MRT station  414 non-null    float64\n",
      " 3   X4 number of convenience stores         414 non-null    int64  \n",
      " 4   X5 latitude                             414 non-null    float64\n",
      " 5   X6 longitude                            414 non-null    float64\n",
      " 6   Y house price of unit area              414 non-null    float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 22.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1 transaction date</th>\n",
       "      <td>414.0</td>\n",
       "      <td>2013.148971</td>\n",
       "      <td>0.281967</td>\n",
       "      <td>2012.66700</td>\n",
       "      <td>2012.917000</td>\n",
       "      <td>2013.16700</td>\n",
       "      <td>2013.417000</td>\n",
       "      <td>2013.58300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2 house age</th>\n",
       "      <td>414.0</td>\n",
       "      <td>17.712560</td>\n",
       "      <td>11.392485</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.025000</td>\n",
       "      <td>16.10000</td>\n",
       "      <td>28.150000</td>\n",
       "      <td>43.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <td>414.0</td>\n",
       "      <td>1083.885689</td>\n",
       "      <td>1262.109595</td>\n",
       "      <td>23.38284</td>\n",
       "      <td>289.324800</td>\n",
       "      <td>492.23130</td>\n",
       "      <td>1454.279000</td>\n",
       "      <td>6488.02100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <td>414.0</td>\n",
       "      <td>4.094203</td>\n",
       "      <td>2.945562</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5 latitude</th>\n",
       "      <td>414.0</td>\n",
       "      <td>24.969030</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>24.93207</td>\n",
       "      <td>24.963000</td>\n",
       "      <td>24.97110</td>\n",
       "      <td>24.977455</td>\n",
       "      <td>25.01459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6 longitude</th>\n",
       "      <td>414.0</td>\n",
       "      <td>121.533361</td>\n",
       "      <td>0.015347</td>\n",
       "      <td>121.47353</td>\n",
       "      <td>121.528085</td>\n",
       "      <td>121.53863</td>\n",
       "      <td>121.543305</td>\n",
       "      <td>121.56627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y house price of unit area</th>\n",
       "      <td>414.0</td>\n",
       "      <td>37.980193</td>\n",
       "      <td>13.606488</td>\n",
       "      <td>7.60000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>38.45000</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>117.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        count         mean          std  \\\n",
       "X1 transaction date                     414.0  2013.148971     0.281967   \n",
       "X2 house age                            414.0    17.712560    11.392485   \n",
       "X3 distance to the nearest MRT station  414.0  1083.885689  1262.109595   \n",
       "X4 number of convenience stores         414.0     4.094203     2.945562   \n",
       "X5 latitude                             414.0    24.969030     0.012410   \n",
       "X6 longitude                            414.0   121.533361     0.015347   \n",
       "Y house price of unit area              414.0    37.980193    13.606488   \n",
       "\n",
       "                                               min          25%         50%  \\\n",
       "X1 transaction date                     2012.66700  2012.917000  2013.16700   \n",
       "X2 house age                               0.00000     9.025000    16.10000   \n",
       "X3 distance to the nearest MRT station    23.38284   289.324800   492.23130   \n",
       "X4 number of convenience stores            0.00000     1.000000     4.00000   \n",
       "X5 latitude                               24.93207    24.963000    24.97110   \n",
       "X6 longitude                             121.47353   121.528085   121.53863   \n",
       "Y house price of unit area                 7.60000    27.700000    38.45000   \n",
       "\n",
       "                                                75%         max  \n",
       "X1 transaction date                     2013.417000  2013.58300  \n",
       "X2 house age                              28.150000    43.80000  \n",
       "X3 distance to the nearest MRT station  1454.279000  6488.02100  \n",
       "X4 number of convenience stores            6.000000    10.00000  \n",
       "X5 latitude                               24.977455    25.01459  \n",
       "X6 longitude                             121.543305   121.56627  \n",
       "Y house price of unit area                46.600000   117.50000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading & describing the data \n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/Regression-4.csv', delimiter = ',')\n",
    "display(df.info())\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Train - Test splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:, -1].values \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling the Train - Test splits\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(np.c_[X_train,y_train])\n",
    "\n",
    "A_train = scaler.transform(np.c_[X_train,y_train])\n",
    "X_train = A_train[:,:-1]\n",
    "y_train = A_train[:,-1]\n",
    "\n",
    "A_test = scaler.transform(np.c_[X_test,y_test])\n",
    "X_test = A_test[:,:-1]\n",
    "y_test = A_test[:,-1]\n",
    "\n",
    "# print(A_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE using OLS is: 0.3840946602349498\n",
      "The MSE using Ridge is: 0.3793714233792295\n",
      "The MSE using Lasso is: 0.3788784599125441\n"
     ]
    }
   ],
   "source": [
    "# Regression Analysis: Mean Squared Error Metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "## OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg1 = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "y_pred1 = reg1.predict(X_test)\n",
    "print('The MSE using OLS is:', mean_squared_error(y_test, y_pred1))\n",
    "\n",
    "\n",
    "## Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "reg2 = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3], fit_intercept=False,cv=10).fit(X_train, y_train)\n",
    "y_pred2 = reg2.predict(X_test)\n",
    "print('The MSE using Ridge is:', mean_squared_error(y_test, y_pred2))\n",
    "\n",
    "\n",
    "## Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "reg3 = LassoCV(alphas=[1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3], \n",
    "               fit_intercept=False,cv=10, random_state=0).fit(X_train, y_train)\n",
    "y_pred3 = reg3.predict(X_test)\n",
    "print('The MSE using Lasso is:', mean_squared_error(y_test, y_pred3))\n",
    "\n",
    "#best_beta =  np.round(reg3.coef_,2)\n",
    "#best_beta_0 = np.round(reg3.intercept_,2)\n",
    "#print(f'The best values for the estimates are :', best_beta_0, best_beta.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best penalty coefficient is: 0.01\n",
      "The best coefficient estimates are: [ 1.07962770e-01 -1.87811814e-01 -4.08893754e-01  2.28328947e-01\n",
      "  2.14423679e-01 -3.65142883e-04]\n"
     ]
    }
   ],
   "source": [
    "## Details of the best estimates\n",
    "print('The best penalty coefficient is:', reg3.alpha_)\n",
    "print('The best coefficient estimates are:', reg3.coef_)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
